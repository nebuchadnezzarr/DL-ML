{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VERA_NN_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nebuchadnezzarr/DL-ML/blob/master/face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_2sFBKqajby",
        "colab_type": "code",
        "outputId": "9f530937-5497-468d-810b-8ddc1daf9ddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "repo_url = 'https://github.com/oarriaga/face_classification.git'\n",
        "\n",
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'face_classification'...\n",
            "remote: Enumerating objects: 887, done.\u001b[K\n",
            "remote: Total 887 (delta 0), reused 0 (delta 0), pack-reused 887\u001b[K\n",
            "Receiving objects: 100% (887/887), 121.29 MiB | 40.05 MiB/s, done.\n",
            "Resolving deltas: 100% (492/492), done.\n",
            "[Errno 2] No such file or directory: '/content/face_classification.git'\n",
            "/content\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0girvNUh99s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
        "from keras.layers import AveragePooling2D, BatchNormalization\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import SeparableConv2D\n",
        "from keras import layers\n",
        "from keras.regularizers import l2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fngcVJHSiPqO",
        "colab_type": "code",
        "outputId": "2ebd8dab-7dcf-46f9-99ff-97a6f831542a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n",
        "    regularization = l2(l2_regularization)\n",
        "\n",
        "    # основа\n",
        "    img_input = Input(input_shape)\n",
        "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
        "               use_bias=False)(img_input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
        "               use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # модуль 1\n",
        "    residual = Conv2D(16, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    # модуль 2\n",
        "    residual = Conv2D(32, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    # модуль 3\n",
        "    residual = Conv2D(64, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    # модуль 4\n",
        "    residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
        "                        kernel_regularizer=regularization,\n",
        "                        use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    x = Conv2D(num_classes, (3, 3),\n",
        "               # kernel_regularizer=regularization,\n",
        "               padding='same')(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    output = Activation('softmax', name='predictions')(x)\n",
        "\n",
        "    model = Model(img_input, output)\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_shape = (64, 64, 1)\n",
        "    num_classes = 7\n",
        "\n",
        "    model = mini_XCEPTION(input_shape, num_classes)\n",
        "    model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 62, 62, 8)    72          input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 62, 62, 8)    32          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 62, 62, 8)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 60, 60, 8)    576         activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 60, 60, 8)    32          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 60, 60, 8)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 60, 60, 16)   200         activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 60, 60, 16)   64          separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 60, 60, 16)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 60, 60, 16)   400         activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 60, 60, 16)   64          separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 30, 30, 16)   128         activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 30, 30, 16)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 30, 30, 16)   64          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 30, 30, 16)   0           max_pooling2d_5[0][0]            \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 30, 30, 32)   656         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 30, 30, 32)   128         separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 30, 30, 32)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 30, 30, 32)   1312        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 30, 30, 32)   128         separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 15, 15, 32)   512         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 15, 15, 32)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 15, 15, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 15, 15, 32)   0           max_pooling2d_6[0][0]            \n",
            "                                                                 batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_13 (SeparableC (None, 15, 15, 64)   2336        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 15, 15, 64)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_14 (SeparableC (None, 15, 15, 64)   4672        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 64)     2048        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 64)     0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 64)     0           max_pooling2d_7[0][0]            \n",
            "                                                                 batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_15 (SeparableC (None, 8, 8, 128)    8768        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 128)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_16 (SeparableC (None, 8, 8, 128)    17536       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 4, 4, 128)    8192        add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 128)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 4, 4, 128)    512         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 4, 4, 128)    0           max_pooling2d_8[0][0]            \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 4, 4, 7)      8071        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 7)            0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Activation)        (None, 7)            0           global_average_pooling2d_2[0][0] \n",
            "==================================================================================================\n",
            "Total params: 58,423\n",
            "Trainable params: 56,951\n",
            "Non-trainable params: 1,472\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dyc9ELbiTGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Программный листинг модуля data_augmentation.\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from keras.utils import to_categorical\n",
        "import scipy.ndimage as ndi\n",
        "import cv2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfave7FtjgCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageGenerator(object):\n",
        "\n",
        "    def __init__(self, ground_truth_data, batch_size, image_size,\n",
        "                 train_keys, validation_keys,\n",
        "                 ground_truth_transformer=None,\n",
        "                 path_prefix=None,\n",
        "                 saturation_var=0.5,\n",
        "                 brightness_var=0.5,\n",
        "                 contrast_var=0.5,\n",
        "                 lighting_std=0.5,\n",
        "                 horizontal_flip_probability=0.5,\n",
        "                 vertical_flip_probability=0.5,\n",
        "                 do_random_crop=False,\n",
        "                 grayscale=False,\n",
        "                 zoom_range=[0.75, 1.25],\n",
        "                 translation_factor=.3):\n",
        "\n",
        "        self.ground_truth_data = ground_truth_data\n",
        "        self.ground_truth_transformer = ground_truth_transformer\n",
        "        self.batch_size = batch_size\n",
        "        self.path_prefix = path_prefix\n",
        "        self.train_keys = train_keys\n",
        "        self.validation_keys = validation_keys\n",
        "        self.image_size = image_size\n",
        "        self.grayscale = grayscale\n",
        "        self.color_jitter = []\n",
        "        if saturation_var:\n",
        "            self.saturation_var = saturation_var\n",
        "            self.color_jitter.append(self.saturation)\n",
        "        if brightness_var:\n",
        "            self.brightness_var = brightness_var\n",
        "            self.color_jitter.append(self.brightness)\n",
        "        if contrast_var:\n",
        "            self.contrast_var = contrast_var\n",
        "            self.color_jitter.append(self.contrast)\n",
        "        self.lighting_std = lighting_std\n",
        "        self.horizontal_flip_probability = horizontal_flip_probability\n",
        "        self.vertical_flip_probability = vertical_flip_probability\n",
        "        self.do_random_crop = do_random_crop\n",
        "        self.zoom_range = zoom_range\n",
        "        self.translation_factor = translation_factor\n",
        "\n",
        "    def _do_random_crop(self, image_array):\n",
        "        height = image_array.shape[0]\n",
        "        width = image_array.shape[1]\n",
        "        x_offset = np.random.uniform(0, self.translation_factor * width)\n",
        "        y_offset = np.random.uniform(0, self.translation_factor * height)\n",
        "        offset = np.array([x_offset, y_offset])\n",
        "        scale_factor = np.random.uniform(self.zoom_range[0],\n",
        "                                         self.zoom_range[1])\n",
        "        crop_matrix = np.array([[scale_factor, 0],\n",
        "                                [0, scale_factor]])\n",
        "\n",
        "        image_array = np.rollaxis(image_array, axis=-1, start=0)\n",
        "        image_channel = [ndi.interpolation.affine_transform(image_channel,\n",
        "                         crop_matrix, offset=offset, order=0, mode='nearest',\n",
        "                         cval=0.0) for image_channel in image_array]\n",
        "\n",
        "        image_array = np.stack(image_channel, axis=0)\n",
        "        image_array = np.rollaxis(image_array, 0, 3)\n",
        "        return image_array\n",
        "\n",
        "    def do_random_rotation(self, image_array):\n",
        "\n",
        "        height = image_array.shape[0]\n",
        "        width = image_array.shape[1]\n",
        "        x_offset = np.random.uniform(0, self.translation_factor * width)\n",
        "        y_offset = np.random.uniform(0, self.translation_factor * height)\n",
        "        offset = np.array([x_offset, y_offset])\n",
        "        scale_factor = np.random.uniform(self.zoom_range[0],\n",
        "                                         self.zoom_range[1])\n",
        "        crop_matrix = np.array([[scale_factor, 0],\n",
        "                                [0, scale_factor]])\n",
        "\n",
        "        image_array = np.rollaxis(image_array, axis=-1, start=0)\n",
        "        image_channel = [ndi.interpolation.affine_transform(image_channel,\n",
        "                         crop_matrix, offset=offset, order=0, mode='nearest',\n",
        "                         cval=0.0) for image_channel in image_array]\n",
        "\n",
        "        image_array = np.stack(image_channel, axis=0)\n",
        "        image_array = np.rollaxis(image_array, 0, 3)\n",
        "        return image_array\n",
        "\n",
        "    def _gray_scale(self, image_array):\n",
        "        return image_array.dot([0.299, 0.587, 0.114])\n",
        "\n",
        "    def saturation(self, image_array):\n",
        "        gray_scale = self._gray_scale(image_array)\n",
        "        alpha = 2.0 * np.random.random() * self.brightness_var\n",
        "        alpha = alpha + 1 - self.saturation_var\n",
        "        image_array = (alpha * image_array + (1 - alpha) *\n",
        "                       gray_scale[:, :, None])\n",
        "        return np.clip(image_array, 0, 255)\n",
        "\n",
        "    def brightness(self, image_array):\n",
        "        alpha = 2 * np.random.random() * self.brightness_var\n",
        "        alpha = alpha + 1 - self.saturation_var\n",
        "        image_array = alpha * image_array\n",
        "        return np.clip(image_array, 0, 255)\n",
        "\n",
        "    def contrast(self, image_array):\n",
        "        gray_scale = (self._gray_scale(image_array).mean() *\n",
        "                      np.ones_like(image_array))\n",
        "        alpha = 2 * np.random.random() * self.contrast_var\n",
        "        alpha = alpha + 1 - self.contrast_var\n",
        "        image_array = image_array * alpha + (1 - alpha) * gray_scale\n",
        "        return np.clip(image_array, 0, 255)\n",
        "\n",
        "    def lighting(self, image_array):\n",
        "        covariance_matrix = np.cov(image_array.reshape(-1, 3) /\n",
        "                                   255.0, rowvar=False)\n",
        "        eigen_values, eigen_vectors = np.linalg.eigh(covariance_matrix)\n",
        "        noise = np.random.randn(3) * self.lighting_std\n",
        "        noise = eigen_vectors.dot(eigen_values * noise) * 255\n",
        "        image_array = image_array + noise\n",
        "        return np.clip(image_array, 0, 255)\n",
        "\n",
        "    def horizontal_flip(self, image_array, box_corners=None):\n",
        "        if np.random.random() < self.horizontal_flip_probability:\n",
        "            image_array = image_array[:, ::-1]\n",
        "            if box_corners is not None:\n",
        "                box_corners[:, [0, 2]] = 1 - box_corners[:, [2, 0]]\n",
        "        return image_array, box_corners\n",
        "\n",
        "    def vertical_flip(self, image_array, box_corners=None):\n",
        "        if (np.random.random() < self.vertical_flip_probability):\n",
        "            image_array = image_array[::-1]\n",
        "            if box_corners is not None:\n",
        "                box_corners[:, [1, 3]] = 1 - box_corners[:, [3, 1]]\n",
        "        return image_array, box_corners\n",
        "\n",
        "    def transform(self, image_array, box_corners=None):\n",
        "        shuffle(self.color_jitter)\n",
        "        for jitter in self.color_jitter:\n",
        "            image_array = jitter(image_array)\n",
        "\n",
        "        if self.lighting_std:\n",
        "            image_array = self.lighting(image_array)\n",
        "\n",
        "        if self.horizontal_flip_probability > 0:\n",
        "            image_array, box_corners = self.horizontal_flip(image_array,\n",
        "                                                            box_corners)\n",
        "\n",
        "        if self.vertical_flip_probability > 0:\n",
        "            image_array, box_corners = self.vertical_flip(image_array,\n",
        "                                                          box_corners)\n",
        "        return image_array, box_corners\n",
        "\n",
        "    def preprocess_images(self, image_array):\n",
        "        return preprocess_input(image_array)\n",
        "\n",
        "    def flow(self, mode='train'):\n",
        "            while True:\n",
        "                if mode == 'train':\n",
        "                    shuffle(self.train_keys)\n",
        "                    keys = self.train_keys\n",
        "                elif mode == 'val' or mode == 'demo':\n",
        "                    shuffle(self.validation_keys)\n",
        "                    keys = self.validation_keys\n",
        "                else:\n",
        "                    raise Exception('invalid mode: %s' % mode)\n",
        "\n",
        "                inputs = []\n",
        "                targets = []\n",
        "                for key in keys:\n",
        "                    image_path = self.path_prefix + key\n",
        "                    image_array = imread(image_path)\n",
        "                    image_array = imresize(image_array, self.image_size)\n",
        "\n",
        "                    num_image_channels = len(image_array.shape)\n",
        "                    if num_image_channels != 3:\n",
        "                        continue\n",
        "\n",
        "                    ground_truth = self.ground_truth_data[key]\n",
        "\n",
        "                    if self.do_random_crop:\n",
        "                        image_array = self._do_random_crop(image_array)\n",
        "\n",
        "                    image_array = image_array.astype('float32')\n",
        "                    if mode == 'train' or mode == 'demo':\n",
        "                        if self.ground_truth_transformer is not None:\n",
        "                            image_array, ground_truth = self.transform(\n",
        "                                                                image_array,\n",
        "                                                                ground_truth)\n",
        "                            ground_truth = (\n",
        "                                self.ground_truth_transformer.assign_boxes(\n",
        "                                                            ground_truth))\n",
        "                        else:\n",
        "                            image_array = self.transform(image_array)[0]\n",
        "\n",
        "                    if self.grayscale:\n",
        "                        image_array = cv2.cvtColor(\n",
        "                                image_array.astype('uint8'),\n",
        "                                cv2.COLOR_RGB2GRAY).astype('float32')\n",
        "                        image_array = np.expand_dims(image_array, -1)\n",
        "\n",
        "                    inputs.append(image_array)\n",
        "                    targets.append(ground_truth)\n",
        "                    if len(targets) == self.batch_size:\n",
        "                        inputs = np.asarray(inputs)\n",
        "                        targets = np.asarray(targets)\n",
        "     \n",
        "                        targets = to_categorical(targets)\n",
        "                        if mode == 'train' or mode == 'val':\n",
        "                            inputs = self.preprocess_images(inputs)\n",
        "                            yield self._wrap_in_dictionary(inputs, targets)\n",
        "                        if mode == 'demo':\n",
        "                            yield self._wrap_in_dictionary(inputs, targets)\n",
        "                        inputs = []\n",
        "                        targets = []\n",
        "\n",
        "    def _wrap_in_dictionary(self, image_array, targets):\n",
        "        return [{'input_1': image_array},\n",
        "                {'predictions': targets}]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd0Rk-HLjmT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Программный листинг модуля datasets.\n",
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "\n",
        "class DataManager(object):\n",
        "    \"\"\"Класс для загрузки баз данных fer2013 и imdb\"\"\"\n",
        "    def __init__(self, dataset_name='imdb',\n",
        "                 dataset_path=None, image_size=(48, 48)):\n",
        "\n",
        "        self.dataset_name = dataset_name\n",
        "        self.dataset_path = dataset_path\n",
        "        self.image_size = image_size\n",
        "        if self.dataset_path is not None:\n",
        "            self.dataset_path = dataset_path\n",
        "        elif self.dataset_name == 'imdb':\n",
        "            self.dataset_path = '../datasets/imdb_crop/imdb.mat'\n",
        "        elif self.dataset_name == 'fer2013':\n",
        "            self.dataset_path = '../datasets/fer2013/fer2013.csv'\n",
        "        elif self.dataset_name == 'KDEF':\n",
        "            self.dataset_path = '../datasets/KDEF/'\n",
        "        else:\n",
        "            raise Exception(\n",
        "                    'Incorrect dataset name, please input imdb or fer2013')\n",
        "\n",
        "    def get_data(self):\n",
        "        if self.dataset_name == 'imdb':\n",
        "            ground_truth_data = self._load_imdb()\n",
        "        elif self.dataset_name == 'fer2013':\n",
        "            ground_truth_data = self._load_fer2013()\n",
        "        elif self.dataset_name == 'KDEF':\n",
        "            ground_truth_data = self._load_KDEF()\n",
        "        return ground_truth_data\n",
        "\n",
        "    def _load_imdb(self):\n",
        "        face_score_treshold = 3\n",
        "        dataset = loadmat(self.dataset_path)\n",
        "        image_names_array = dataset['imdb']['full_path'][0, 0][0]\n",
        "        gender_classes = dataset['imdb']['gender'][0, 0][0]\n",
        "        face_score = dataset['imdb']['face_score'][0, 0][0]\n",
        "        second_face_score = dataset['imdb']['second_face_score'][0, 0][0]\n",
        "        face_score_mask = face_score > face_score_treshold\n",
        "        second_face_score_mask = np.isnan(second_face_score)\n",
        "        unknown_gender_mask = np.logical_not(np.isnan(gender_classes))\n",
        "        mask = np.logical_and(face_score_mask, second_face_score_mask)\n",
        "        mask = np.logical_and(mask, unknown_gender_mask)\n",
        "        image_names_array = image_names_array[mask]\n",
        "        gender_classes = gender_classes[mask].tolist()\n",
        "        image_names = []\n",
        "        for image_name_arg in range(image_names_array.shape[0]):\n",
        "            image_name = image_names_array[image_name_arg][0]\n",
        "            image_names.append(image_name)\n",
        "        return dict(zip(image_names, gender_classes))\n",
        "\n",
        "    def _load_fer2013(self):\n",
        "        data = pd.read_csv(self.dataset_path)\n",
        "        pixels = data['pixels'].tolist()\n",
        "        width, height = 48, 48\n",
        "        faces = []\n",
        "        for pixel_sequence in pixels:\n",
        "            face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
        "            face = np.asarray(face).reshape(width, height)\n",
        "            face = cv2.resize(face.astype('uint8'), self.image_size)\n",
        "            faces.append(face.astype('float32'))\n",
        "        faces = np.asarray(faces)\n",
        "        faces = np.expand_dims(faces, -1)\n",
        "        emotions = pd.get_dummies(data['emotion']).as_matrix()\n",
        "        return faces, emotions\n",
        "\n",
        "    def _load_KDEF(self):\n",
        "        class_to_arg = get_class_to_arg(self.dataset_name)\n",
        "        num_classes = len(class_to_arg)\n",
        "\n",
        "        file_paths = []\n",
        "        for folder, subfolders, filenames in os.walk(self.dataset_path):\n",
        "            for filename in filenames:\n",
        "                if filename.lower().endswith(('.jpg')):\n",
        "                    file_paths.append(os.path.join(folder, filename))\n",
        "\n",
        "        num_faces = len(file_paths)\n",
        "        y_size, x_size = self.image_size\n",
        "        faces = np.zeros(shape=(num_faces, y_size, x_size))\n",
        "        emotions = np.zeros(shape=(num_faces, num_classes))\n",
        "        for file_arg, file_path in enumerate(file_paths):\n",
        "            image_array = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "            image_array = cv2.resize(image_array, (y_size, x_size))\n",
        "            faces[file_arg] = image_array\n",
        "            file_basename = os.path.basename(file_path)\n",
        "            file_emotion = file_basename[4:6]\n",
        "            try:\n",
        "                emotion_arg = class_to_arg[file_emotion]\n",
        "            except:\n",
        "                continue\n",
        "            emotions[file_arg, emotion_arg] = 1\n",
        "        faces = np.expand_dims(faces, -1)\n",
        "        return faces, emotions\n",
        "\n",
        "\n",
        "def get_labels(dataset_name):\n",
        "    if dataset_name == 'fer2013':\n",
        "        return {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy',\n",
        "                4: 'sad', 5: 'surprise', 6: 'neutral'}\n",
        "    elif dataset_name == 'imdb':\n",
        "        return {0: 'woman', 1: 'man'}\n",
        "    elif dataset_name == 'KDEF':\n",
        "        return {0: 'AN', 1: 'DI', 2: 'AF', 3: 'HA', 4: 'SA', 5: 'SU', 6: 'NE'}\n",
        "    else:\n",
        "        raise Exception('Invalid dataset name')\n",
        "\n",
        "\n",
        "def get_class_to_arg(dataset_name='fer2013'):\n",
        "    if dataset_name == 'fer2013':\n",
        "        return {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'sad': 4,\n",
        "                'surprise': 5, 'neutral': 6}\n",
        "    elif dataset_name == 'imdb':\n",
        "        return {'woman': 0, 'man': 1}\n",
        "    elif dataset_name == 'KDEF':\n",
        "        return {'AN': 0, 'DI': 1, 'AF': 2, 'HA': 3, 'SA': 4, 'SU': 5, 'NE': 6}\n",
        "    else:\n",
        "        raise Exception('Invalid dataset name')\n",
        "\n",
        "\n",
        "def split_imdb_data(ground_truth_data, validation_split=.2, do_shuffle=False):\n",
        "    ground_truth_keys = sorted(ground_truth_data.keys())\n",
        "    if do_shuffle is not False:\n",
        "        shuffle(ground_truth_keys)\n",
        "    training_split = 1 - validation_split\n",
        "    num_train = int(training_split * len(ground_truth_keys))\n",
        "    train_keys = ground_truth_keys[:num_train]\n",
        "    validation_keys = ground_truth_keys[num_train:]\n",
        "    return train_keys, validation_keys\n",
        "\n",
        "\n",
        "def split_data(x, y, validation_split=.2):\n",
        "    num_samples = len(x)\n",
        "    num_train_samples = int((1 - validation_split)*num_samples)\n",
        "    train_x = x[:num_train_samples]\n",
        "    train_y = y[:num_train_samples]\n",
        "    val_x = x[num_train_samples:]\n",
        "    val_y = y[num_train_samples:]\n",
        "    train_data = (train_x, train_y)\n",
        "    val_data = (val_x, val_y)\n",
        "    return train_data, val_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31BoDrE4jsyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Программный листинг модуля inference.\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def load_image(image_path, grayscale=False, target_size=None):\n",
        "    pil_image = image.load_img(image_path, grayscale, target_size)\n",
        "    return image.img_to_array(pil_image)\n",
        "\n",
        "def load_detection_model(model_path):\n",
        "    detection_model = cv2.CascadeClassifier(model_path)\n",
        "    return detection_model\n",
        "\n",
        "def detect_faces(detection_model, gray_image_array):\n",
        "    return detection_model.detectMultiScale(gray_image_array, 1.3, 5)\n",
        "\n",
        "def draw_bounding_box(face_coordinates, image_array, color):\n",
        "    x, y, w, h = face_coordinates\n",
        "    cv2.rectangle(image_array, (x, y), (x + w, y + h), color, 2)\n",
        "\n",
        "def apply_offsets(face_coordinates, offsets):\n",
        "    x, y, width, height = face_coordinates\n",
        "    x_off, y_off = offsets\n",
        "    return (x - x_off, x + width + x_off, y - y_off, y + height + y_off)\n",
        "\n",
        "def draw_text(coordinates, image_array, text, color, x_offset=0, y_offset=0,\n",
        "                                                font_scale=2, thickness=2):\n",
        "    x, y = coordinates[:2]\n",
        "    cv2.putText(image_array, text, (x + x_offset, y + y_offset),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                font_scale, color, thickness, cv2.LINE_AA)\n",
        "\n",
        "def get_colors(num_classes):\n",
        "    colors = plt.cm.hsv(np.linspace(0, 1, num_classes)).tolist()\n",
        "    colors = np.asarray(colors) * 255\n",
        "    return colors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Chx6YUbjwFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Программный листинг модуля preprocessor.\n",
        "import numpy as np\n",
        "from imageio import imread\n",
        "\n",
        "\n",
        "def preprocess_input(x, v2=True):\n",
        "    x = x.astype('float32')\n",
        "    x = x / 255.0\n",
        "    if v2:\n",
        "        x = x - 0.5\n",
        "        x = x * 2.0\n",
        "    return x\n",
        "\n",
        "def _imread(image_name):\n",
        "        return imread(image_name)\n",
        "\n",
        "\n",
        "def _imresize(image_array, size):\n",
        "        return imresize(image_array, size)\n",
        "\n",
        "\n",
        "def to_categorical(integer_classes, num_classes=2):\n",
        "    integer_classes = np.asarray(integer_classes, dtype='int')\n",
        "    num_samples = integer_classes.shape[0]\n",
        "    categorical = np.zeros((num_samples, num_classes))\n",
        "    categorical[np.arange(num_samples), integer_classes] = 1\n",
        "    return categorical\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjzuy62NsxvM",
        "colab_type": "code",
        "outputId": "684ea165-ca6c-42a0-d53c-c032f85e8d06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "data = pd.read_csv('./fer2013.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-27b72dd7dee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./fer2013.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./fer2013.csv' does not exist: b'./fer2013.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU-Bv7-ykXdk",
        "colab_type": "code",
        "outputId": "a35829ea-f82f-4508-d7ed-7cd0787f3a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Программный листинг модуля train_emotion_classifier.\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/face_classification/src\")\n",
        " \n",
        "from keras.applications import Xception\n",
        "from datasets import DataManager\n",
        "from datasets import split_data\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "# параметры\n",
        "batch_size = 32\n",
        "num_epochs = 10000\n",
        "input_shape = (64, 64, 1)\n",
        "validation_split = .2\n",
        "verbose = 1\n",
        "num_classes = 7\n",
        "patience = 50\n",
        "base_path = '../trained_models/emotion_models/'\n",
        "\n",
        "# генератор данных\n",
        "data_generator = ImageDataGenerator(\n",
        "                        featurewise_center=False,\n",
        "                        featurewise_std_normalization=False,\n",
        "                        rotation_range=10,\n",
        "                        width_shift_range=0.1,\n",
        "                        height_shift_range=0.1,\n",
        "                        zoom_range=.1,\n",
        "                        horizontal_flip=True)\n",
        "\n",
        "# параметры модели\n",
        "model = mini_XCEPTION(input_shape, num_classes)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "datasets = ['fer2013']\n",
        "for dataset_name in datasets:\n",
        "    print('Training dataset:', dataset_name)\n",
        "\n",
        "    # обратные вызовы\n",
        "    log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
        "    csv_logger = CSVLogger(log_file_path, append=False)\n",
        "    early_stop = EarlyStopping('val_loss', patience=patience)\n",
        "    reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
        "                                  patience=int(patience/4), verbose=1)\n",
        "    trained_models_path = base_path + dataset_name + '_mini_XCEPTION'\n",
        "    model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
        "    model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
        "                                                    save_best_only=True)\n",
        "    callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
        "\n",
        "    # загрузка базы данных\n",
        "    data_loader = DataManager(dataset_name, image_size=input_shape[:2])\n",
        "    faces, emotions = data_loader.get_data()\n",
        "    faces = preprocess_input(faces)\n",
        "    num_samples, num_classes = emotions.shape\n",
        "    train_data, val_data = split_data(faces, emotions, validation_split)\n",
        "    train_faces, train_emotions = train_data\n",
        "    model.fit_generator(data_generator.flow(train_faces, train_emotions,\n",
        "                                            batch_size),\n",
        "                        steps_per_epoch=len(train_faces) / batch_size,\n",
        "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
        "                        validation_data=val_data)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 62, 62, 8)    72          input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 62, 62, 8)    32          conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 62, 62, 8)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 60, 60, 8)    576         activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 60, 60, 8)    32          conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 60, 60, 8)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_49 (SeparableC (None, 60, 60, 16)   200         activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 60, 60, 16)   64          separable_conv2d_49[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 60, 60, 16)   0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_50 (SeparableC (None, 60, 60, 16)   400         activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 60, 60, 16)   64          separable_conv2d_50[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 30, 30, 16)   128         activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling2D) (None, 30, 30, 16)   0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 30, 30, 16)   64          conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 30, 30, 16)   0           max_pooling2d_25[0][0]           \n",
            "                                                                 batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_51 (SeparableC (None, 30, 30, 32)   656         add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 30, 30, 32)   128         separable_conv2d_51[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 30, 30, 32)   0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_52 (SeparableC (None, 30, 30, 32)   1312        activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 30, 30, 32)   128         separable_conv2d_52[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 15, 15, 32)   512         add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling2D) (None, 15, 15, 32)   0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 15, 15, 32)   128         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 15, 15, 32)   0           max_pooling2d_26[0][0]           \n",
            "                                                                 batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_53 (SeparableC (None, 15, 15, 64)   2336        add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_53[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 15, 15, 64)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_54 (SeparableC (None, 15, 15, 64)   4672        activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_54[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 8, 8, 64)     2048        add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling2D) (None, 8, 8, 64)     0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 64)     256         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 8, 8, 64)     0           max_pooling2d_27[0][0]           \n",
            "                                                                 batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_55 (SeparableC (None, 8, 8, 128)    8768        add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_55[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 8, 8, 128)    0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_56 (SeparableC (None, 8, 8, 128)    17536       activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_56[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 128)    8192        add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling2D) (None, 4, 4, 128)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 4, 4, 128)    512         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 4, 4, 128)    0           max_pooling2d_28[0][0]           \n",
            "                                                                 batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 7)      8071        add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_7 (Glo (None, 7)            0           conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Activation)        (None, 7)            0           global_average_pooling2d_7[0][0] \n",
            "==================================================================================================\n",
            "Total params: 58,423\n",
            "Trainable params: 56,951\n",
            "Non-trainable params: 1,472\n",
            "__________________________________________________________________________________________________\n",
            "Training dataset: fer2013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-eca0a1edc879>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# загрузка базы данных\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memotions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/face_classification/src/utils/datasets.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mground_truth_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_imdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fer2013'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mground_truth_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_fer2013\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'KDEF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mground_truth_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_KDEF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/face_classification/src/utils/datasets.py\u001b[0m in \u001b[0;36m_load_fer2013\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_fer2013\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mpixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pixels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../datasets/fer2013/fer2013.csv' does not exist: b'../datasets/fer2013/fer2013.csv'"
          ]
        }
      ]
    }
  ]
}